\relax 
\citation{Shin2016Learning,deepika2018classification,iakovidis2012image}
\citation{Shin2016Learning}
\citation{hochreiter1997long}
\citation{timmurphy.org}
\citation{Wang2017ChestX}
\citation{yao2017learning}
\citation{Rajpurkar2017CheXNet}
\citation{Wang2018TieNet}
\citation{Franquet2001Imaging,Thomas2005Standardized}
\citation{korfiatis2009texture}
\citation{Yorozu1987Electron}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{intro}{{I}{1}}
\citation{wu2018master}
\citation{frisoni2010clinical,coupe2012simultaneous,moradi2015machine,liu2018joint}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the proposed Multimodal Pneumonia Detection Network (MPDNet) for pneumonia detection. The inputs of this models are three-channel CT images, clinical chief complaints and demographic information. A RCNN (Recurrent Convolutional Neural Network) is used to capture the visual features. A LSTM is used to analyse chief complaints. Visual features, chief complaints and demographic information will be fed into a multimodal regression network.}}{2}}
\newlabel{Illustration}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Overview of the MPDNet. The black box in the left indicates raw inputs from the hospital.The grey rectangle contains demographic information about age and gender; the blue rectangle contains chief complaints; the green rectangle provides CT image data. Chief complaints will be transformed into matrices by Word2vec and analyze by one LSTM network. Images will be fed into RCNN. Age and gender will be treated as two confounding factors. These three kinds of information will be concatenated and fed into the regression model to simulate the clinical process.}}{2}}
\newlabel{architecture}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Material and Data Processing}{3}}
\newlabel{datasetprocessing}{{II}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Material Preparation}{3}}
\newlabel{ctimagedata}{{\unhbox \voidb@x \hbox {II-A}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Prepare of CT Image Data}{3}}
\newlabel{ctimagedata}{{\unhbox \voidb@x \hbox {II-B}}{3}}
\citation{Shin2017Three,gao2018holistic}
\citation{dukart2011age,de2016machine}
\citation{liu2018joint}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Data pre-process for CT scans. Each scan will be transformed into three images with different windows (yellow arrows). Then three images will be compressed into one three-channel false-color image (green arrows).}}{4}}
\newlabel{3channelprocess}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Examples of three-channel images. In this figure, void space (in red rectangle) in original CT images is not very obvious since other normal tissues are in black too. But in the three-channel images, we notice the differences between normal tissues and low dense tissues. Moreover, the details of high dense tissues (in the white rectangle) are still kept in three-channel images.}}{4}}
\newlabel{3channel}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Prepare of Demographic and Clinical Data}{4}}
\newlabel{textdata}{{\unhbox \voidb@x \hbox {II-C}}{4}}
\citation{mikolov2013efficient,mikolov2013distributed}
\citation{Donahue2015Long,Aafaq2019Spatio}
\citation{Zreik2018A}
\citation{chung2014empirical}
\citation{tseng2017joint}
\citation{lin2014network}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Series with Different `Convolutional Kernel'. Generally speaking, a case of CT contain several series. Each series has specific `Convolutional Kernel', which indicates image windows or data types. As shown in this figure, slice under `B70s' has clearer view of lungs, slice under `B41s' has a more unobstructed view of the heart. `Patient Protocol' and `Topogram' contain some basic parameters of CT equipment or information about radiologists, which are not suitable for CNN. In our study, we will design a protocol to select the most suitable series for CNN models. In this case, we will choose `B70s' as the image inputs of the model, which is also the most commonly used CT image window in clinic.}}{5}}
\newlabel{Bs}{{3}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces }}{5}}
\newlabel{malefemale}{{I}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Multimodal Pneumonia Detection Network }{5}}
\newlabel{MPDNetwork}{{III}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Construction of RCNN}{5}}
\newlabel{RCNN}{{\unhbox \voidb@x \hbox {III-A}}{5}}
\newlabel{hvt}{{1}{5}}
\citation{ILSVRC15}
\citation{simonyan2015very}
\citation{he2016deep}
\citation{szegedy2016rethinking}
\citation{Wang2017ChestX}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Construction of MPDNet}{6}}
\newlabel{MMDDtxt}{{\unhbox \voidb@x \hbox {III-B}}{6}}
\newlabel{hct}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{6}}
\newlabel{experiments}{{IV}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Experimental Setup}{6}}
\newlabel{experimentalsetup}{{\unhbox \voidb@x \hbox {IV-A}}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Analysis of Three-Channel Images and Different RCNN Models}{6}}
\newlabel{effectiveness}{{\unhbox \voidb@x \hbox {IV-B}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Convolutional Feature Maps from CNN Models Trained by Different Images. The top row shows a pneumonia case which has abnormally low dense areas (white rectangles). The middle row shows a pneumonia case which has abnormal high dense areas (yellow rectangles). During convolutional process, three-channel images can provide both high dense and low dense information. However, low attenuation images can only provide low dense information, high attenuation images can only provide high dense information. Moreover, lung window images have difficulty in distinguishing low dense tissues form normal lung tissues. The bottom row is a healthy case. We can compare healthy lung tissues with abnormal low dense tissues and abnormal high dense tissues. }}{7}}
\newlabel{show}{{6}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Comparison of All Kinds of RCNN}}{7}}
\newlabel{rcnncompare}{{II}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Analysis of Clinical and Demographic Information}{7}}
\newlabel{complaintsagegender}{{\unhbox \voidb@x \hbox {IV-C}}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces }}{8}}
\newlabel{frequency1}{{III}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Chief complaints can provide information related to CT images. In this figure, we show two pneumonia cases, and each case has chief complaints provided by patients. Words marked red give the location, and words marked blue provide symptoms. English chief complaints are translated from Chinese above. Location and symptoms information provided by chief complaints are related to abnormal tissues in CT images.}}{8}}
\newlabel{txtpic}{{7}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Performances of RCNN and MPDNet in Validation Set}}{9}}
\newlabel{mpdnetres}{{IV}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparison between RCNN trained with lung window images, RCNN trained with high attenuation images, RCNN trained with three-channel images without auxiliary loss, RCNN trained with three-channel images, MPDNet trained with chief complaints and MPDNet. We compare these five models in accuracy, sensitivity, and specificity.}}{9}}
\newlabel{figureALL}{{8}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Evaluation}{9}}
\newlabel{results}{{\unhbox \voidb@x \hbox {IV-D}}{9}}
\citation{Donahue2015Long}
\citation{Donahue2015Long}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Confusion matrices achieved by eight different methods in in detection results. We have 144 pneumonia cases and 86 healthy cases in validation set. LW: Lung Window Image, HA: High Attenuation Image, LA: Low Attenuation Image, TC: Three-Channel Image}}{10}}
\newlabel{Confusionmatrices}{{9}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Validation accuracy and loss during training.}}{10}}
\newlabel{loss}{{10}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Discussion}{10}}
\newlabel{discuss}{{V}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Parameter Analysis}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Limitations and Future Work}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Validation accuracy of RCNN models with different number of LSTM units. All experiments here have the same parameters except the number of LSTM unit in RCNN. RCNN with 128 LSTM units achieves the highest validation accuracy.}}{10}}
\newlabel{LSTMNumber}{{11}{10}}
\bibstyle{IEEEtran}
\bibdata{refs}
\bibcite{Shin2016Learning}{1}
\bibcite{deepika2018classification}{2}
\bibcite{iakovidis2012image}{3}
\bibcite{hochreiter1997long}{4}
\bibcite{timmurphy.org}{5}
\bibcite{Wang2017ChestX}{6}
\bibcite{yao2017learning}{7}
\bibcite{Rajpurkar2017CheXNet}{8}
\bibcite{Wang2018TieNet}{9}
\bibcite{Franquet2001Imaging}{10}
\bibcite{Thomas2005Standardized}{11}
\bibcite{korfiatis2009texture}{12}
\bibcite{Yorozu1987Electron}{13}
\bibcite{wu2018master}{14}
\bibcite{frisoni2010clinical}{15}
\bibcite{coupe2012simultaneous}{16}
\bibcite{moradi2015machine}{17}
\bibcite{liu2018joint}{18}
\bibcite{Shin2017Three}{19}
\bibcite{gao2018holistic}{20}
\bibcite{dukart2011age}{21}
\bibcite{de2016machine}{22}
\bibcite{mikolov2013efficient}{23}
\bibcite{mikolov2013distributed}{24}
\bibcite{Donahue2015Long}{25}
\bibcite{Aafaq2019Spatio}{26}
\bibcite{Zreik2018A}{27}
\bibcite{chung2014empirical}{28}
\bibcite{tseng2017joint}{29}
\bibcite{lin2014network}{30}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{11}}
\newlabel{conclude}{{VI}{11}}
\@writefile{toc}{\contentsline {section}{References}{11}}
\bibcite{ILSVRC15}{31}
\bibcite{simonyan2015very}{32}
\bibcite{he2016deep}{33}
\bibcite{szegedy2016rethinking}{34}
\@writefile{toc}{\contentsline {section}{Biographies}{12}}
\@writefile{toc}{\contentsline {subsection}{Qiuli\nobreakspace  {}Wang}{12}}
\@writefile{toc}{\contentsline {subsection}{Zhihuan\nobreakspace  {}Li}{12}}
\@writefile{toc}{\contentsline {subsection}{Chen\nobreakspace  {}Liu}{12}}
\@writefile{toc}{\contentsline {subsection}{Dan\nobreakspace  {}Yang}{12}}
\@writefile{toc}{\contentsline {subsection}{Xiaohong\nobreakspace  {}Zhang}{12}}

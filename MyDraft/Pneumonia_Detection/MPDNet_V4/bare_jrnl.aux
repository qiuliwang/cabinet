\relax 
\citation{Shin2016Learning,deepika2018classification,iakovidis2012image}
\citation{Shin2016Learning}
\citation{hochreiter1997long}
\citation{timmurphy.org}
\citation{Wang2017ChestX}
\citation{yao2017learning}
\citation{Rajpurkar2017CheXNet}
\citation{Wang2018TieNet}
\citation{Franquet2001Imaging,Thomas2005Standardized}
\citation{korfiatis2009texture}
\citation{Yorozu1987Electron}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{intro}{{I}{1}}
\citation{wu2018master}
\citation{frisoni2010clinical,coupe2012simultaneous,moradi2015machine,liu2018joint}
\newlabel{Illustration}{{I}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the proposed Multimodal Pneumonia Detection Network (MPDNet) for pneumonia detection. There are four main elements: (a) CT image processing; (b) visual features extraction from three channels; (c) clinical and demographic information processing; and (d) multimodal regression network for pneumonia detection}}{2}}
\citation{Shin2017Three,gao2018holistic}
\citation{dukart2011age,de2016machine}
\citation{liu2018joint}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Scans under Different `Convolutional Kernel'. Slice under `B70s' has clearer view of lungs, slice under `B41s' has a more unobstructed view of the heart. `Patient Protocol' and `Topogram' contain some basic parameters of CT equipment or information about radiologists, which are not suitable for CNN.}}{3}}
\newlabel{Bs}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Material and Data Processing}{3}}
\newlabel{datasetprocessing}{{II}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Material Preparation}{3}}
\newlabel{ctimagedata}{{\unhbox \voidb@x \hbox {II-A}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Pre-processing of CT Image Data}{3}}
\newlabel{ctimagedata}{{\unhbox \voidb@x \hbox {II-B}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Prepare of Demographic and Clinical Data}{3}}
\newlabel{textdata}{{\unhbox \voidb@x \hbox {II-C}}{3}}
\citation{mikolov2013efficient,mikolov2013distributed}
\citation{Donahue2015Long,Aafaq2019Spatio}
\citation{Zreik2018A}
\citation{chung2014empirical}
\citation{tseng2017joint}
\citation{Donahue2015Long}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Sub-figure (a) shows data pre-process for CT scans. Each scan will be transformed into three images with different windows (yellow arrow). Then three images will be compressed into one three-channel false-color image (green arrow). Sub-figure (b) exhibits examples of three-channel images. In this figure, void space (in red rectangle) in original CT images is not very obvious since other normal tissues are in black too. But in the three-channel images, we notice the difference between normal tissues and low dense tissues. Moreover, the details of high dense tissues (in the white rectangle) are still kept. }}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Data Pre-precess for CT Scans}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Three-Channel Images}}}{4}}
\newlabel{3channel}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Multimodal Pneumonia Detection Network }{4}}
\newlabel{MPDNetwork}{{III}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Construction of RCNN}{4}}
\newlabel{RCNN}{{\unhbox \voidb@x \hbox {III-A}}{4}}
\citation{lin2014network}
\citation{Zreik2018A}
\citation{szegedy2016rethinking}
\citation{ILSVRC15}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces }}{5}}
\newlabel{malefemale}{{I}{5}}
\newlabel{hvt}{{1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Construction of MPDNet}{5}}
\newlabel{MMDDtxt}{{\unhbox \voidb@x \hbox {III-B}}{5}}
\newlabel{hct}{{2}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{5}}
\newlabel{experiments}{{IV}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Experimental Setup}{5}}
\newlabel{experimentalsetup}{{\unhbox \voidb@x \hbox {IV-A}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Overview of the MPDNet. The black box in the left indicates raw information from the hospital. In the black box, the information in the grey rectangle is about age and gender; the information in the blue rectangle is chief complaints; the information in yellow rectangle is CT image data. Chief complaints will be transformed into matrices by Word2vec and analyze by one LSTM network. Images will be fed into RCNN. LW (Lung Window), HA (High Attenuation), LA (Low Attenuation) in the green box represent three image window: lung window, high attenuation window, and low attenuation window. Age and gender will be treated as two additional features. These three kinds of information will be concatenated in the red rectangle and simulate the clinical process.}}{6}}
\newlabel{architecture}{{4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Analysis of Clinical and Demographic Information}{6}}
\newlabel{complaintsagegender}{{\unhbox \voidb@x \hbox {IV-B}}{6}}
\citation{simonyan2015very}
\citation{he2016deep}
\citation{szegedy2016rethinking}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces }}{7}}
\newlabel{frequency1}{{II}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Analysis of Three-Channel Image and Auxiliary Loss}{7}}
\newlabel{effectiveness}{{\unhbox \voidb@x \hbox {IV-C}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Chief complaints can provide information related to CT images. In this figure, we show two pneumonic cases, and each case has chief complaints provided by patients. Words marked red give the location, and words marked blue provide symptoms. English chief complaints are translated from Chinese above. Location and symptoms information provided by chief complaints are related to abnormal tissues in CT images.}}{7}}
\newlabel{txtpic}{{5}{7}}
\citation{Wang2017ChestX}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Convolutional Feature Maps from CNN Models Trained by Different Images. In the first row, three-channel CNN can capture the low dense tissues of lungs, which are not very clear in LW (Lung Window) CNN and HA (High Attenuation) CNN. LA (Low Attenuation) CNN can notice the low dense tissues, but the details of heart and vessels are ignored in the low attenuation CNN. In the second row, three-channel CNN still can capture high dense tissues, which is the same as LW CNN and HA CNN, but LA CNN has difficulty in doing so. The last row shows a healthy case. The healthy case has a clear view in LW CNN, HA CNN, and three-channel CNN, but shows nothing in LA CNN.}}{8}}
\newlabel{show}{{6}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Comparison of All Kinds of RCNN and MPDNet}}{8}}
\newlabel{rcnncompare}{{III}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Comparison of All Kinds of RCNN and MPDNet}}{9}}
\newlabel{mpdnetres}{{IV}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Comparison between RCNN trained with lung window images, RCNN trained with high attenuation images, RCNN trained with three-channel images without auxiliary loss, RCNN trained with three-channel images, MPDNet trained with chief complaints and MPDNet. We compare these seven models in accuracy, sensitivity, specificity and AUROC.}}{9}}
\newlabel{figureALL}{{7}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Results on Clinical Data}{9}}
\newlabel{results}{{\unhbox \voidb@x \hbox {IV-D}}{9}}
\bibstyle{IEEEtran}
\bibdata{refs}
\bibcite{Shin2016Learning}{1}
\bibcite{deepika2018classification}{2}
\bibcite{iakovidis2012image}{3}
\bibcite{hochreiter1997long}{4}
\bibcite{timmurphy.org}{5}
\bibcite{Wang2017ChestX}{6}
\bibcite{yao2017learning}{7}
\bibcite{Rajpurkar2017CheXNet}{8}
\bibcite{Wang2018TieNet}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Sub-figure (a) shows the validation loss during training; Sub-figure (b) shows the validation accuracy during training. We can see that MPDNet's performance outperforms others.}}{10}}
\newlabel{loss}{{8}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Discussion}{10}}
\newlabel{discuss}{{V}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Parameter Analysis}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Limitations and Future Work}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{10}}
\newlabel{conclude}{{VI}{10}}
\@writefile{toc}{\contentsline {section}{References}{10}}
\bibcite{Franquet2001Imaging}{10}
\bibcite{Thomas2005Standardized}{11}
\bibcite{korfiatis2009texture}{12}
\bibcite{Yorozu1987Electron}{13}
\bibcite{wu2018master}{14}
\bibcite{frisoni2010clinical}{15}
\bibcite{coupe2012simultaneous}{16}
\bibcite{moradi2015machine}{17}
\bibcite{liu2018joint}{18}
\bibcite{Shin2017Three}{19}
\bibcite{gao2018holistic}{20}
\bibcite{dukart2011age}{21}
\bibcite{de2016machine}{22}
\bibcite{mikolov2013efficient}{23}
\bibcite{mikolov2013distributed}{24}
\bibcite{Donahue2015Long}{25}
\bibcite{Aafaq2019Spatio}{26}
\bibcite{Zreik2018A}{27}
\bibcite{chung2014empirical}{28}
\bibcite{tseng2017joint}{29}
\bibcite{lin2014network}{30}
\bibcite{szegedy2016rethinking}{31}
\bibcite{ILSVRC15}{32}
\bibcite{simonyan2015very}{33}
\bibcite{he2016deep}{34}
\@writefile{toc}{\contentsline {section}{Biographies}{11}}
\@writefile{toc}{\contentsline {subsection}{Qiuli\nobreakspace  {}Wang}{11}}
\@writefile{toc}{\contentsline {subsection}{Zhihuan\nobreakspace  {}Li}{11}}
\@writefile{toc}{\contentsline {subsection}{Chen\nobreakspace  {}Liu}{11}}
\@writefile{toc}{\contentsline {subsection}{Dan\nobreakspace  {}Yang}{12}}
\@writefile{toc}{\contentsline {subsection}{Xiaohong\nobreakspace  {}Zhang}{12}}

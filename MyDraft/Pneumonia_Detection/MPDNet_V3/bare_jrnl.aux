\relax 
\citation{Shin2016Learning,deepika2018classification,iakovidis2012image}
\citation{Shin2016Learning}
\citation{hochreiter1997long}
\citation{timmurphy.org}
\citation{Wang2017ChestX}
\citation{yao2017learning}
\citation{Rajpurkar2017CheXNet}
\citation{Wang2018TieNet}
\citation{Franquet2001Imaging,Thomas2005Standardized}
\citation{korfiatis2009texture}
\citation{Yorozu1987Electron}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{intro}{{I}{1}}
\citation{wu2018master}
\citation{frisoni2010clinical,coupe2012simultaneous,moradi2015machine,liu2018joint}
\newlabel{Illustration}{{I}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the proposed Multimodal Pneumonia Detection Network (MPDNet) for pneumonia detection. There are four main elements: (a) CT image processing; (b) visual features extraction from three channels; (c) clinical and demographic information processing; and (d) multimodal regression network for pneumonia detection}}{2}}
\citation{Shin2017Three,gao2018holistic}
\citation{dukart2011age,de2016machine}
\citation{liu2018joint}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Scans under Different `Convolutional Kernel'. Slice under `B70s' has clearer view of lungs, slice under `B41s' has a more unobstructed view of the heart. `Patient Protocol' and `Topogram' contain some basic parameters of CT equipment or information about radiologists, which are not suitable for CNN.}}{3}}
\newlabel{Bs}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Material and Image Processing}{3}}
\newlabel{datasetprocessing}{{II}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Data Generation}{3}}
\newlabel{ctimagedata}{{\unhbox \voidb@x \hbox {II-A}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Data Pre-processing}{3}}
\newlabel{ctimagedata}{{\unhbox \voidb@x \hbox {II-B}1}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-B}1}Pre-processing of CT Image Data}{3}}
\newlabel{textdata}{{\unhbox \voidb@x \hbox {II-B}2}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-B}2}Pre-processing of Demographic and Clinical Data}{3}}
\citation{mikolov2013efficient,mikolov2013distributed}
\citation{Donahue2015Long,Aafaq2019Spatio}
\citation{Zreik2018A}
\citation{chung2014empirical}
\citation{tseng2017joint}
\citation{Donahue2015Long}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Sub-figure (a) shows data pre-process for CT scans. Each scan will be transformed into three images with different windows (yellow arrow). Then three images will be compressed into one three-channel false-color image (green arrow). Sub-figure (b) exhibits examples of three-channel images. In this figure, void space (in red rectangle) in original CT images is not very obvious since other normal tissues are in black too. But in the three-channel images, we notice the difference between normal tissues and low dense tissues. Moreover, the details of high dense tissues (in the white rectangle) are still kept. }}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Data Pre-precess for CT Scans}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Three-Channel Images}}}{4}}
\newlabel{3channel}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Multimodal Pneumonia Detection Network }{4}}
\newlabel{MPDNetwork}{{III}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Construction of RCNN}{4}}
\newlabel{RCNN}{{\unhbox \voidb@x \hbox {III-A}}{4}}
\citation{lin2014network}
\newlabel{architecture}{{III}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Overview of the proposed MPDNet. The input data include three-channel CT slices, clinical and demographic information (i.e., chief complaints, age and gender) of each subject. The output is the regression result, which indicates whether this subject is pneumonic. Note that the term `a' in `$a@b \times b$' denotes the number of kernels, while `$b \times b$' represents the size of a 2D convolutional kernel.}}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces }}{5}}
\newlabel{malefemale}{{I}{5}}
\newlabel{hvt}{{1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Construction of MPDNet}{5}}
\newlabel{MMDDtxt}{{\unhbox \voidb@x \hbox {III-B}}{5}}
\citation{Zreik2018A}
\citation{szegedy2016rethinking}
\citation{ILSVRC15}
\citation{simonyan2015very}
\citation{he2016deep}
\citation{szegedy2016rethinking}
\citation{Wang2017ChestX}
\newlabel{hct}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{6}}
\newlabel{experiments}{{IV}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Experimental Setup}{6}}
\newlabel{experimentalsetup}{{\unhbox \voidb@x \hbox {IV-A}}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Analysis of Three-Channel Image and Auxiliary Loss}{6}}
\newlabel{effectiveness}{{\unhbox \voidb@x \hbox {IV-B}}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Comparison of All Kinds of RCNN and MPDNet}}{7}}
\newlabel{rcnncompare}{{II}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Convolutional Feature Maps from CNN Models Trained by Different Images. In the first row, three-channel CNN can capture the low dense tissues of lungs, which are not very clear in LW (Lung Window) CNN and HA (High Attenuation) CNN. LA (Low Attenuation) CNN can notice the low dense tissues, but the details of heart and vessels are ignored in the low attenuation CNN. In the second row, three-channel CNN still can capture high dense tissues, which is the same as LW CNN and HA CNN, but LA CNN has difficulty in doing so. The last row shows a healthy case. The healthy case has a clear view in LW CNN, HA CNN, and three-channel CNN, but shows nothing in LA CNN.}}{7}}
\newlabel{show}{{5}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Chief complaints can provide information related to CT images. In this figure, we show two pneumonic cases, and each case has chief complaints provided by patients. Words marked red give the location, and words marked blue provide symptoms. English chief complaints are translated from Chinese above. Location and symptoms information provided by chief complaints are related to abnormal tissues in CT images.}}{8}}
\newlabel{txtpic}{{6}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Analysis of Clinical and Demographic Information}{8}}
\newlabel{complaintsagegender}{{\unhbox \voidb@x \hbox {IV-C}}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Results on Clinical Data}{8}}
\newlabel{results}{{\unhbox \voidb@x \hbox {IV-D}}{8}}
\bibstyle{IEEEtran}
\bibdata{refs}
\bibcite{Shin2016Learning}{1}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces }}{9}}
\newlabel{frequency1}{{III}{9}}
\newlabel{mpdnetres}{{\unhbox \voidb@x \hbox {IV-D}}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Comparison of All Kinds of RCNN and MPDNet}}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Discussion}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{9}}
\newlabel{conclude}{{VI}{9}}
\bibcite{deepika2018classification}{2}
\bibcite{iakovidis2012image}{3}
\bibcite{hochreiter1997long}{4}
\bibcite{timmurphy.org}{5}
\bibcite{Wang2017ChestX}{6}
\bibcite{yao2017learning}{7}
\bibcite{Rajpurkar2017CheXNet}{8}
\bibcite{Wang2018TieNet}{9}
\bibcite{Franquet2001Imaging}{10}
\bibcite{Thomas2005Standardized}{11}
\bibcite{korfiatis2009texture}{12}
\bibcite{Yorozu1987Electron}{13}
\bibcite{wu2018master}{14}
\bibcite{frisoni2010clinical}{15}
\bibcite{coupe2012simultaneous}{16}
\bibcite{moradi2015machine}{17}
\bibcite{liu2018joint}{18}
\bibcite{Shin2017Three}{19}
\bibcite{gao2018holistic}{20}
\bibcite{dukart2011age}{21}
\bibcite{de2016machine}{22}
\bibcite{mikolov2013efficient}{23}
\bibcite{mikolov2013distributed}{24}
\bibcite{Donahue2015Long}{25}
\bibcite{Aafaq2019Spatio}{26}
\bibcite{Zreik2018A}{27}
\bibcite{chung2014empirical}{28}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sub-figure (a) shows the validation loss during training; Sub-figure (b) shows the validation accuracy during training. We can see that MPDNet's performance outperforms others. }}{10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Validation Loss During Training}}}{10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Validation Accuracy During Training}}}{10}}
\newlabel{loss}{{7}{10}}
\@writefile{toc}{\contentsline {section}{References}{10}}
\bibcite{tseng2017joint}{29}
\bibcite{lin2014network}{30}
\bibcite{szegedy2016rethinking}{31}
\bibcite{ILSVRC15}{32}
\bibcite{simonyan2015very}{33}
\bibcite{he2016deep}{34}
\@writefile{toc}{\contentsline {section}{Biographies}{11}}
\@writefile{toc}{\contentsline {subsection}{Qiuli\nobreakspace  {}Wang}{11}}
\@writefile{toc}{\contentsline {subsection}{Zhihuan\nobreakspace  {}Li}{11}}
\@writefile{toc}{\contentsline {subsection}{Chen\nobreakspace  {}Liu}{11}}
\@writefile{toc}{\contentsline {subsection}{Dan\nobreakspace  {}Yang}{11}}
\@writefile{toc}{\contentsline {subsection}{Xiaohong\nobreakspace  {}Zhang}{11}}

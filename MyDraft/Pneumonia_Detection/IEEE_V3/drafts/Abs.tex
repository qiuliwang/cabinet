\emph{Objective:} Pneumonia detection is one of the most crucial steps in pneumonia diagnosing system. Clinical information of patients plays an important role in detection of pneumonia. In is paper, a Multimodal Data Diagnosing Network(MDDNet) is described for clinical pneumonia detection.
\emph{Method:} MDDNet is based on deep learning neural network and analyzes multimodal data. We use Recurrent CNN, which can keep 3-D spatial information and reduce the need of calculation resource, to capture visual features from CT image data. Each slice of CT is transformed into one 3-channel(Lung Window, High Attenuation, Low Attenuation) image which can provide more information of lung density. Meanwhile, patient clinical information like complaint, age and gender is adopted and provides more abundant information to improve the accuracy of pneumonia detection. A Long Short Term Memory(LSTM) network is used to analyze semantic features of patient complaints and provides information which image data cannot provide, like how many days the patient has been ill. Information about age and gender can provide priori information since age and gender is associated with certain kinds of pneumonia. CT visual features, complaint semantic features, patient age and gender will be fused together and calculate joint distribution to predict whether these cases are pneumonic.
\emph{Results:} We analyze 1002 clinical cases from The First Affiliated Hospital of Army Medical University. Our model achieves 0.945 in accuracy, and has a very balanced performance in sensitivity and specificity. As far as we know, we are the first to detect pneumonic cases using large scale clinical multimodal data.
\emph{Conclusion:} Our method proves that multimodal data provides more abundant information than image data only and improves the accuracy of pneumonia detection. 
\emph{Significance:} Our model can be extended and include more kinds of clinical data to give out more reliable and explainable detection results.